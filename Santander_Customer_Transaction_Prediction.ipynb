{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0a0b83",
   "metadata": {},
   "source": [
    "**Autora** : Rafaela Ramos Sarmento\n",
    "\n",
    "**e-mail**: rafaelaramos.datasci@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d7da9",
   "metadata": {},
   "source": [
    "#  <a name=\"resumo\"> RESUMO </a>\n",
    "[Voltar ao índice](#indice)\n",
    "\n",
    "A Base de dados trabalhada é a **'Santander Customer Transaction Prediction'** disponível no link: https://www.kaggle.com/c/santander-customer-transaction-prediction\n",
    "\n",
    "Essa base de dados envolve um problema de classificação binária, isto é, a partir das features disponíveis, decidir se caso é X ou Y, ou de maneira binária, 0 ou 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ada09c",
   "metadata": {},
   "source": [
    "#  <a name=\"indice\">  Índice </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d85f63",
   "metadata": {},
   "source": [
    "* [Resumo](#resumo)\n",
    "* [Índice](#indice)\n",
    "* [Problema a ser analisado](#secao_0)\n",
    "* [Análise descritiva e exploratória](#secao_1)\n",
    "* [Random Forest](#secao_2)\n",
    "* [Regressão Logística](#secao_3)\n",
    "* [GBDT - XGBOOST](#secao_4)\n",
    "* [Redes Neurais](#secao_5)\n",
    "* [Comparação Entre  os Modelos](#secao_6)\n",
    "* [Conclusão do Desafio](#secao_7) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c03dc",
   "metadata": {},
   "source": [
    "#  <a name=\"secao_0\"> Problema a ser analisado </a>\n",
    "[Voltar ao índice](#indice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa92f2e",
   "metadata": {},
   "source": [
    "Como a base de dados escolhida foi a do **'Santander Customer Transaction Prediction'** temos o seguinte texto guia: \n",
    "\n",
    "   * \"In this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem.\" *\n",
    "\n",
    "\n",
    "Como temos um problema de classificação binária, e o próprio desafio sugere que a análise conste como uma previsão de que os clientes do banco realizem uma determinada operação no futuro, dadas as variáveis disponíveis no banco de dados do Santander, podemos formular um problema de negócio em que o banco estará oferecendo para o cliente um investimento de renda fixa do programa “Renda Mais”. Neste caso, os modelos de machine learning tem o objetivo de prever se um dado cliente irá participar do programa ou não.\n",
    "\n",
    "Assim, as variáveis disponíveis poderiam ser interpretados como informações relacionadas a empréstimos realizados e pagos, pagamentos, idade, renda, situação civil e outras trasações e investimentos no banco.\n",
    "\n",
    "Portanto, queremos criar um modelo de previsão que forneça o indicativo sobre quais clientes possuem maior probabilidade de fazer parte do programa \"Renda Mais\", de forma que os clientes classificados positivamente (1) receberão e-mails com propostas e propagandas referentes ao programa de investimento.\n",
    "\n",
    "Para este caso, observa-se que falsos positivos (FP) não são um problema grave, uma vez que um cliente que seja classificado positivamente mas que não tenha interesse no programa poderá apenas ignorar ou recusar a oferta. Entretanto, o caso de falso negativo (FN) é considerado um problema grave, uma vez que o cliente classificado negativamente mas que tenha interesse em investir não recebera a oferta e, assim, o banco perde um cliente em potencial e não haverá lucros. A métrica de classificação de maior importância é o recall, de forma que maximizando o recall estaremos diminuindo o número de falsos negativos.\n",
    "O recall é dado pela equação:\n",
    "\n",
    "\n",
    "$$ recall = \\frac{VP}{VP + FN}$$\n",
    "\n",
    "\n",
    "\n",
    "O problema consta com a variável **ID_code** que é a identificação do cliente, a **target** que é o problema que estamos querendo resolver, isto é, é a variável do tipo classe (binária, 0 ou 1), e teremos um total de **200** features, identificadas como: var_0, var_1, ..., var_199.\n",
    "\n",
    "Um detalhe é que a base de dados de teste não possui a coluna target, então não seria possível verificar as métricas do nosso modelo utilizando esses dados, portanto, o que será feito é dividir a base de treino em duas: uma efetivamente de treino e outra de validação, de forma a ter uma proporção 70% e 30%, respectivamente.\n",
    "Além disso, a base de dados já esta bastante limpa, não sendo necessário fazer um trabalho arduo de pré-processamento dos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2fd9b4",
   "metadata": {},
   "source": [
    "#  <a name=\"secao_1\"> Análise descritiva e exploratória </a>\n",
    "[Voltar ao índice](#indice)\n",
    "\n",
    "Vamos calcular algumas propriedades estatisticas dessa base de dados.\n",
    "\n",
    "   - Não há valores nulos;\n",
    "   - Dados em mesmo range de escala;\n",
    "   - Classes desbalanceadas -> proporção 9 (0) para 1 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43bc8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import statistics as sts\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2f8de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando funcao para ter informacoes sobre os dados\n",
    "def show_info(data) :\n",
    "    print('DATASET SHAPE: ', data.shape, '\\n')\n",
    "    print('-'*50)\n",
    "    print('FEATURE DATA TYPES:')\n",
    "    print(data.info())\n",
    "    print('\\n', '-'*50)\n",
    "    print('NUMBER OF UNIQUE VALUES PER FEATURE:', '\\n')\n",
    "    print(data.nunique())\n",
    "    print('\\n', '-'*50)\n",
    "    print('NULL VALUES PER FEATURE')\n",
    "    print(data.isnull().sum())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ee8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_real, y_previsao, nome_modelo, color_roc = \"pink\") :\n",
    "    rfp, rvp,lim = roc_curve(y_real,  y_previsao)\n",
    "    # Gráfico da curva roc\n",
    "    auc = roc_auc_score(y_real, y_previsao)\n",
    "    plt.plot(rfp, rvp, marker='.', label='%s (AUC = %0.2f)' % (nome_modelo, auc),color=color_roc)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.title('Curva ROC - %s' % nome_modelo, fontsize=15)\n",
    "    plt.xlabel('1- Especificidade', fontsize=12)\n",
    "    plt.ylabel('Sensibilidade', fontsize=12)\n",
    "    plt.grid(color='w', linestyle='dotted', linewidth=1)\n",
    "    plt.legend()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c154275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curva_learning(modelo, nome_modelo) :\n",
    "    results = modelo.evals_result()\n",
    "    # plot learning curves\n",
    "    plt.plot(results['validation_0']['logloss'], label='train')\n",
    "    plt.plot(results['validation_1']['logloss'], label='test')\n",
    "    plt.title('LogLoss vs n_estimator - %s' %nome_modelo)\n",
    "    plt.ylabel('LogLoss')\n",
    "    plt.xlabel('n_estimator')\n",
    "    plt.grid(color='w', linestyle='dotted', linewidth=1)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb1e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../santander-customer-transaction-prediction/train.csv\")\n",
    "df_train, df_validacao = train_test_split(df, train_size=0.7, shuffle=True)\n",
    "\n",
    "#df_test = pd.read_csv(\"santander-customer-transaction-prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62680af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando os arrays para X {variaveis previsoras} e Y {variavel tipo classe} para treino e teste\n",
    "Y_train = df_train.iloc[:, 1].values\n",
    "X_train = df_train.iloc[:, 2:].values\n",
    "Y_validacao = df_validacao.iloc[:, 1].values \n",
    "X_validacao = df_validacao.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92498357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16534482",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_info(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_info(df_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f862b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105e0e2",
   "metadata": {},
   "source": [
    "#### Primeiras observações \n",
    "\n",
    "Legenda para entendimento do problema: \n",
    "   *  ID_code :  identificação do cliente\n",
    "   *  target: variável que queremos prever\n",
    "   *  var_i ; i = 0, 1, ..., 199\n",
    "   \n",
    "observa-se que em ambos conjuntos de dados, treino e validacao, não há valores nulos. Também não será necessário fazer processo de cleaning e escalonamento, visto que as variáveis estão sem significado e as ordens de grandeza estão próximas. \n",
    "\n",
    "Temos um caso de classes desbalanceadas, sendo as contagens:\n",
    "  - Treino:\n",
    "      * classe 0 : 125972 contagens  \n",
    "      * classe 1 : 14028 contagens\n",
    "  - Validação:\n",
    "      * classe 0 : 53930 contagens  \n",
    "      * classe 1 : 6070 contagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validacao.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando a quantidade de cada classe dentro do conjunto de dados de treino\n",
    "sns.countplot(x=df_train['target'], palette = 'RdPu').set_title('target - treino')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee1cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando a quantidade de cada classe dentro do conjunto de dados de validacao\n",
    "sns.countplot(x=df_validacao['target'], palette = 'ocean').set_title('target - validação')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_validacao, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculo da matriz de correlação entre as variáveis do problema\n",
    "plt.figure(figsize=(40,20)) \n",
    "plt.title('Correlação entre as features', size = 50) \n",
    "sns.heatmap(df_train.corr(), cmap='RdPu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b574a",
   "metadata": {},
   "source": [
    "A seguir, o calculo matriz de correlacao, verifica quais entradas é maior que 0.5 e faz a contagem. A diagonal sempre vai valer 1, se tiver 201 contagens nao nulas, entao as variaveis nao sao correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aecf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacao = df_train.corr()\n",
    "qtd_correlacao = np.where(abs(correlacao)>0.5, 1, 0)\n",
    "np.count_nonzero(qtd_correlacao), qtd_correlacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a617bb8",
   "metadata": {},
   "source": [
    "#  <a name=\"secao_2\"> Random Forest </a>\n",
    "[Voltar ao índice](#indice)\n",
    "\n",
    "Vamos iniciar o processo de previsão utilizando um algoritmo mais simples, o Random Forest.\n",
    "\n",
    "Para este caso, foi testado alguns modelos manualmente e após isso foi utilizado o GridSearchCV() para encontrar o melhor modelo dentro de algumas possibilidades de hiper parâmetros. \n",
    "\n",
    "Com o melhor modelo, foi calculado as principais métricas para um caso de classificação, sendo elas a matriz de confusão, precision, recall e a curva ROC. Também foi plotado as 10 features mais importantes para o treino do modelo, essa informação poderia ser utilizada para eliminar features pouco importantes e deixar o treino com um custo computacional menor. Esse ultimo processo não foi feito nessa análise.\n",
    "\n",
    "\n",
    "Parâmetros utilizados e variados:\n",
    "   - n_estimator\n",
    "   - max_depth\n",
    "   - criterion = 'entropy' (fixo)\n",
    "   \n",
    "métrica maximizada: **recall** \n",
    "\n",
    "O melhor modelo, utilizando o GridSearchCV() foi construido usando os seguintes parâmetros:\n",
    "   - n_estimator: 200\n",
    "   - max_depth: 12\n",
    "\n",
    "   \n",
    "Com o recall sendo igual a:\n",
    "   - Recall Score : 0.7235\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54702e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install threadpoolctl==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00202643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, recall_score, roc_auc_score\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from imblearn.over_sampling import BorderlineSMOTE \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_roc_curve, RocCurveDisplay, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d75d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validacao.shape, Y_validacao.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8625f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanceando os dados, de forma a usar a técnica de oversampling\n",
    "smote_random_forest = BorderlineSMOTE(sampling_strategy='minority')\n",
    "X_over_train, Y_over_train = smote_random_forest.fit_resample(X_train, Y_train)\n",
    "X_over_validacao, Y_over_validacao = smote_random_forest.fit_resample(X_validacao, Y_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b7211",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_over_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be305c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_over_validacao, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inciando o treinamento com a Random Forest, usando a metrica para hierarquia das features\n",
    "#a minimizacao da entropia (maximizacao do ganho de informacao)\n",
    "random_forest = RandomForestClassifier(n_estimators=200, criterion='entropy', max_depth=12, verbose=1,random_state = 0)\n",
    "random_forest.fit(X_over_train, Y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_random_forest = random_forest.predict(X_over_validacao)\n",
    "recall_score(Y_over_validacao, previsoes_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85669082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculo de algumas métricas de classificação: matriz de confusao\n",
    "matriz_confusao_random_forest = ConfusionMatrix(random_forest, cmap='GnBu')\n",
    "matriz_confusao_random_forest.fit(X_over_train, Y_over_train)\n",
    "matriz_confusao_random_forest.score(X_over_validacao, Y_over_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printa as métricas de classificação\n",
    "print(classification_report(Y_over_validacao, previsoes_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RocCurveDisplay.from_estimator(random_forest, X_over_validacao, Y_over_validacao, name = 'Random Forest')\n",
    "roc_random_forest = plot_roc_curve(Y_over_validacao, previsoes_random_forest, 'Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1f889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotando o ranking de importancia das features utilizadas para treinar o meu modelo\n",
    "feat_importances = pd.Series(random_forest.feature_importances_)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04047d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tunando os hyperparametros com o gridsearch:\n",
    "parametros = {'criterion': ['entropy'], \n",
    "              'n_estimators': [50, 100, 200],\n",
    "              'max_depth': [6, 9, 12],\n",
    "               'random_state': [0]}  \n",
    "\n",
    "grid_rf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parametros, scoring='recall', cv=2)\n",
    "grid_rf.fit(X_over_train, Y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ebb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Melhor modelo: ' + str(grid_rf.best_estimator_))\n",
    "print('Best Score: ' + str(grid_rf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc35fa3",
   "metadata": {},
   "source": [
    "#  <a name=\"secao_3\"> Regressão Logística </a>\n",
    "[Voltar ao índice](#indice)\n",
    "\n",
    "Tentando um modelo mais simples para verificar como os dados se comportam. Para isso, será utilizado a regressão logística.\n",
    "\n",
    "Parâmetros utilizados e variados:\n",
    "   - max_iter\n",
    "   - solver\n",
    "   \n",
    "métrica maximizada: recall \n",
    "\n",
    "O melhor modelo, utilizando o GridSearchCV() foi construido usando os seguintes parâmetros:\n",
    "   - max_iter: 1500\n",
    "   - solver: 'lbfgs'\n",
    "   \n",
    "Com o recall sendo igual a:\n",
    "   - recall: 0.8037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1500, random_state = 0)\n",
    "logistic_regression.fit(X_over_train, Y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d871123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic_regression.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73553c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_logistic = logistic_regression.predict(X_over_validacao)\n",
    "recall_score(Y_over_validacao, previsoes_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e127ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao_logistic = ConfusionMatrix(logistic_regression, cmap='GnBu')\n",
    "matriz_confusao_logistic.fit(X_over_train, Y_over_train)\n",
    "matriz_confusao_logistic.score(X_over_validacao, Y_over_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4992fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_over_validacao, previsoes_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_logistic = plot_roc_curve(Y_over_validacao, previsoes_logistic, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tunando os hiperparametros da logistic regression com o GridSearchCV()\n",
    "parametros_logistic = {'max_iter': [100, 300, 500, 1000, 1500],\n",
    "                   'solver': ['lbfgs', 'saga'],\n",
    "               }  \n",
    "\n",
    "grid_logistic= GridSearchCV(estimator=LogisticRegression(), param_grid=parametros_logistic, cv=2, scoring='recall', verbose=0)\n",
    "grid_logistic.fit(X_over_train, Y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95de529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Melhor modelo: ' + str(grid_logistic.best_estimator_))\n",
    "print('Best Score: ' + str(grid_logistic.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389722b4",
   "metadata": {},
   "source": [
    "#  <a name=\"secao_4\"> GBDT - XGBOOST </a>\n",
    "[Voltar ao índice](#indice)\n",
    "\n",
    "Utilizando a GBDT, um algoritmo mais avançado, em que teremos um ensemble de decisions trees trabalhando de forma sequencial. A GBDT aqui é implementada pela biblioteca XGBoost.\n",
    "\n",
    "Parâmetros utilizados e variados:\n",
    "   - n_estimator\n",
    "   - max_depth\n",
    "   - learning_rate\n",
    "\n",
    "métrica maximizada: recall \n",
    "\n",
    "O melhor modelo, utilizando o GridSearchCV() foi construido usando os seguintes parâmetros:\n",
    "   - n_estimator: 200\n",
    "   - max_depth: 9\n",
    "   - learning_rate: 0.3 \n",
    "   \n",
    "Com o recall sendo igual a:\n",
    "   - recall: 0.7417\n",
    "\n",
    "Entretanto, este modelo overfitou, assim, os parâmetros foram atualizados e adicionou-se um parâmetro de regularização (L2 - reg_gamma). De forma, que obteve-se o resultado:\n",
    "   - n_estimator: 500\n",
    "   - max_depth: 4\n",
    "   - learning_rate: 0.1 \n",
    "   \n",
    "Com o recall sendo igual a:\n",
    "   - recall: 0.8284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d46370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import xgboost as get_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b23d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#treinando modelo com os dados já balanceados pela etapa do random forest\n",
    "GBDT = xgb.XGBClassifier(n_estimators=500, max_depth=4, learning_rate=0.1,random_state=0, reg_lambda=0.1)\n",
    "GBDT.fit(X_over_train, Y_over_train, eval_metric='logloss', eval_set=[(X_over_train, Y_over_train), (X_over_validacao, Y_over_validacao)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab57674",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_gbdt = GBDT.predict(X_over_validacao)\n",
    "recall_score(Y_over_validacao, previsoes_gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculo de algumas métricas de classificação: matriz de confusao\n",
    "matriz_confusao_gbdt = ConfusionMatrix(GBDT, cmap='GnBu')\n",
    "matriz_confusao_gbdt.fit(X_over_train, Y_over_train)\n",
    "matriz_confusao_gbdt.score(X_over_validacao, Y_over_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fdea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printa as métricas de classificação\n",
    "print(classification_report(Y_over_validacao, previsoes_gbdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_gbdt = plot_roc_curve(Y_over_validacao, previsoes_gbdt, 'GBDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fc08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss_gbdt = plot_curva_learning(GBDT, 'GBDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(GBDT.feature_importances_)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tunando os hiperparametros da GBDT com o GridSearchCV()\n",
    "parametros_gbdt = {'n_estimators': [100, 150, 200],\n",
    "              'max_depth': [3, 6, 9],\n",
    "                   'learning_rate': [0.1],\n",
    "               }  \n",
    "\n",
    "grid_gbdt = GridSearchCV(estimator=xgb.XGBClassifier(), param_grid=parametros_gbdt, cv=2, scoring='recall', verbose=0)\n",
    "grid_gbdt.fit(X_over_train, Y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Melhor modelo: ' + str(grid_gbdt.best_estimator_))\n",
    "print('Best Score: ' + str(grid_gbdt.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b817be1",
   "metadata": {},
   "source": [
    "#  <a name=\"secao_5\"> Redes Neurais </a>\n",
    "[Voltar ao índice](#indice)\n",
    "\n",
    "Para a aplicação de redes neurais para resolver o problema, será utilizado uma rede neural simples, implementada pelo sklearn, a MLPClassifier()   (MultiLayer Perceptron).\n",
    "\n",
    "Parâmetros utilizados e variados:\n",
    "   - max_iter (epocas)\n",
    "   - activation = 'logistic'\n",
    "   - hidden_layer_sizes \n",
    "   \n",
    "métrica maximizada: recall \n",
    "\n",
    "O melhor modelo encontrado:\n",
    "   - max_iter (epocas) = 300 (efetivos=78)\n",
    "   - hidden_layer_sizes = (100, 50, 25, 13,7) \n",
    "   \n",
    "Com o recall sendo igual a:\n",
    "   - recall: 0.7827\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de19e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca162c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200 (neuronios entrada) -> 100 (1 camada oculta com 100 neuronios) -> 1 (neuronio saida)\n",
    "rede_neural = MLPClassifier(max_iter=300, verbose=True, hidden_layer_sizes = (100, 50, 25, 13,7), activation='logistic', random_state=0)\n",
    "rede_neural.fit(X_over_train, Y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_rn = rede_neural.predict(X_over_validacao)\n",
    "recall_score(Y_over_validacao, previsoes_rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedca433",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao_rn = ConfusionMatrix(rede_neural, cmap='GnBu')\n",
    "matriz_confusao_rn.fit(X_over_train, Y_over_train)\n",
    "matriz_confusao_rn.score(X_over_validacao, Y_over_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4efdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_over_validacao, previsoes_rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_redeneural = plot_roc_curve(Y_over_validacao, previsoes_rn, 'Rede Neural (MLP)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9fe7c1",
   "metadata": {},
   "source": [
    "#  <a name=\"secao_6\"> Comparação Entre os Modelos </a>\n",
    "[Voltar ao índice](#indice)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b32c6",
   "metadata": {},
   "source": [
    "Os modelos foram avaliados segundo a métrica **recall**. De forma que, resumidamente, obtivemos os seguintes resultados:\n",
    "\n",
    "   -  **Random Forest**: 0.72\n",
    "   - **Regressão Logistica**: 0.80\n",
    "   - **GBDT**: 0.82\n",
    "   - **Rede Neural**: 0.78    \n",
    "   \n",
    "Com isso, olhando apenas para o recall, a GBDT demonstrou possuir uma melhor performance, apesar de ter apresentado overfiting com o modelo retornado pelo GridSearchCV(). \n",
    "A GBDT também apresenta uma melhor curva ROC, estando mais localizada ao canto superior esquerdo do gráfico, sua AUC foi igual a 0.88."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cafcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(Y_over_validacao, previsoes_random_forest, 'Random Forest', 'lightseagreen')\n",
    "plot_roc_curve(Y_over_validacao, previsoes_logistic, 'Regressão Logística', 'darkolivegreen')\n",
    "plot_roc_curve(Y_over_validacao, previsoes_gbdt, 'GBDT', 'red')\n",
    "plot_roc_curve(Y_over_validacao, previsoes_rn, 'Rede Neural (MLP)', 'orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ece9c",
   "metadata": {},
   "source": [
    "#  <a name=\"secao_7\"> Conclusão do desafio </a>\n",
    "[Voltar ao índice](#indice)\n",
    "\n",
    "Como o problema proposto no desafio era bastante aberto, foi escolhido uma abordagem exploratória de modelos de Machine Learning para realizar a previsão de uma possível tranasação envolvendo clientes do banco Santander. O problema envolveu um banco de dados do Kaggle e consistiu de um problema de classificação binária, também preferido pelo enunciado do desafio. \n",
    "\n",
    "O pré processamento foi curto uma vez que o dados eram bastante limpos e comportados, bastando apenas de um processo de balanceamento, no qual se usou uma técnica de oversampling. A análise preditiva de classificação buscou testar desde os modelos mais simples, como a Regressão Logística, até os mais sofisticados, como o GBDT. O que se observou foi que apesar do nivel de complexidade entre estas duas técnicas ser bastante diferente, ambas retornaram um valor de recall bastante próximos, de forma que o custo-benefício tende a Regressão Logística. \n",
    "\n",
    "O pior valor encontrado foi referente ao Random Forest.\n",
    "\n",
    "A verificação de overfitting foi realizada apenas para o GBDT, mas poderia ter sido feito para todos os demais modelos. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
